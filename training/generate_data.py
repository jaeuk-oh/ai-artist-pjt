"""Synthetic í•™ìŠµ ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (LLM API í™œìš©)."""

import json
import os
from pathlib import Path

from anthropic import Anthropic

PERSONA_PROMPT = """ë‹¹ì‹ ì€ K-Pop ê·¸ë£¹ NOVAì˜ ë©”ì¸ë³´ì»¬ ìœ ë¦¬(YURI, 21ì„¸, ë§‰ë‚´)ì…ë‹ˆë‹¤.
íŒ¬ê³¼ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ë§íˆ¬ íŠ¹ì§•:
- ë°˜ë§ ê¸°ë³¸, ê°„í—ì  ì¡´ëŒ“ë§ í˜¼ìš©
- ì´ëª¨ì§€ ì ì ˆíˆ ì‚¬ìš© (ğŸ˜ŠğŸ’–âœ¨ğŸ¤ğŸŒŸ)
- ë°ê³  ì—ë„ˆì§€ ë„˜ì¹¨
- íŒ¬ ì´ë¦„ ìì—°ìŠ¤ëŸ½ê²Œ í˜¸ëª…"""

CATEGORIES = {
    "persona": "ì¼ìƒ ëŒ€í™”, íŒ¬ ì‘ì›, ì—°ìŠµ ì´ì•¼ê¸°, ë¬´ëŒ€ ì†Œê°",
    "worldview": "ê·¸ë£¹ NOVA, SUPERNOVA ì•¨ë²”, ë©¤ë²„ í•˜ëŠ˜/ì†Œì´ì— ëŒ€í•œ Q&A",
    "safety": "ì—°ì•  ìƒë‹´, ì •ì¹˜ì  ì§ˆë¬¸, íƒ€ ê·¸ë£¹ ë¹„í•˜ ë“± ê±°ë¶€ ì‘ë‹µ",
}


def generate_conversation(client: Anthropic, category: str, description: str) -> dict:
    prompt = f"""{PERSONA_PROMPT}

ì¹´í…Œê³ ë¦¬: {category}
ì£¼ì œ: {description}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ íŒ¬-ìœ ë¦¬ ëŒ€í™” 1ìŒì„ JSONìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”:
{{
  "messages": [
    {{"role": "user", "content": "íŒ¬ì˜ ë©”ì‹œì§€"}},
    {{"role": "assistant", "content": "ìœ ë¦¬ì˜ ë‹µë³€"}}
  ],
  "category": "{category}"
}}"""

    response = client.messages.create(
        model="claude-sonnet-4-6",
        max_tokens=500,
        messages=[{"role": "user", "content": prompt}],
    )
    text = response.content[0].text
    start = text.find("{")
    end = text.rfind("}") + 1
    return json.loads(text[start:end])


def main(n_samples_per_category: int = 10):
    client = Anthropic()
    output_dir = Path("data/datasets")

    for category, description in CATEGORIES.items():
        output_dir.joinpath(category).mkdir(parents=True, exist_ok=True)
        samples = []

        print(f"Generating {n_samples_per_category} samples for [{category}]...")
        for i in range(n_samples_per_category):
            try:
                sample = generate_conversation(client, category, description)
                samples.append(sample)
                print(f"  [{i+1}/{n_samples_per_category}] generated")
            except Exception as e:
                print(f"  Error at sample {i+1}: {e}")

        split = int(len(samples) * 0.9)
        for split_name, data in [("train", samples[:split]), ("eval", samples[split:])]:
            out_path = output_dir / category / f"{split_name}.jsonl"
            with open(out_path, "w", encoding="utf-8") as f:
                for item in data:
                    f.write(json.dumps(item, ensure_ascii=False) + "\n")
            print(f"  Saved {len(data)} samples to {out_path}")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--n", type=int, default=10, help="samples per category")
    args = parser.parse_args()
    main(n_samples_per_category=args.n)
